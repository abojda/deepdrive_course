{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5DHHYu1UQIY"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download deepdrive_course repository when running in Google Colab (to have access to libraries)**"
      ],
      "metadata": {
        "id": "ywzS0HYCCJR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "if in_colab:\n",
        "  !git clone https://github.com/abojda/deepdrive_course.git dd_course\n",
        "  !pip install dd_course/ -q"
      ],
      "metadata": {
        "id": "5KC6zGcGAPS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7D9wfnibxAK"
      },
      "outputs": [],
      "source": [
        "!python3 -m pip install pytorch-lightning timm opencv-python gdown patool optuna mega.py -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import pytorch_lightning as pl"
      ],
      "metadata": {
        "id": "tZUsfbGgk9LO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELmrDr1Bg93Y"
      },
      "source": [
        "## wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31_obIkog9S2"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKkkQ3dZv012"
      },
      "source": [
        "## Setup model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "9EonaNwiv3FI"
      },
      "outputs": [],
      "source": [
        "from deepdrive_course.resisc45.modules import ResiscLit\n",
        "from deepdrive_course.utils import download_from_mega_nz, timm_prepare_params_for_training\n",
        "\n",
        "\n",
        "def get_model(config):\n",
        "  # Create TIMM model\n",
        "  timm_model = timm.create_model(config['timm_model'],\n",
        "                                pretrained=config['timm_pretrained'],\n",
        "                                num_classes=len(RESISC45.classes),\n",
        "                                drop_rate=config['timm_dropout'])\n",
        "\n",
        "\n",
        "  # Create ResiscLit (pl.LightningModule)\n",
        "  if config['checkpoint'] == None:\n",
        "    model = ResiscLit(timm_model, config)\n",
        "    print('[ResiscLit] No checkpoint - training from scratch')\n",
        "\n",
        "  elif config['checkpoint'].endswith('.ckpt'):\n",
        "    model = ResiscLit.load_from_checkpoint(\n",
        "        config['checkpoint'],\n",
        "        model=timm_model,\n",
        "        config=config)\n",
        "\n",
        "    print(f'[ResiscLit] Loaded local checkpoint: {config[\"checkpoint\"]}')\n",
        "\n",
        "  elif 'mega.nz' in config['checkpoint']:\n",
        "    checkpoint_path = download_from_mega_nz(config['checkpoint'])\n",
        "\n",
        "    model = ResiscLit.load_from_checkpoint(\n",
        "      checkpoint_path,\n",
        "      model=timm_model,\n",
        "      config=config)\n",
        "\n",
        "    print(f'[ResiscLit] Loaded mega.nz checkpoint: {checkpoint_path}')\n",
        "\n",
        "  else:\n",
        "    raise ValueError(config['checkpoint'])\n",
        "\n",
        "\n",
        "  # Transfer learning / full training setup\n",
        "  timm_prepare_params_for_training(model.model, config['training_type'])\n",
        "  print(f'Training type: {config[\"training_type\"]}')\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup datamodule"
      ],
      "metadata": {
        "id": "_zeqKxi1kYsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepdrive_course.resisc45.datamodules import RESISC45DataModule\n",
        "from deepdrive_course.resisc45.transforms import get_transform\n",
        "from deepdrive_course.utils import timm_get_pretrained_data_transform\n",
        "\n",
        "def get_datamodule(config):\n",
        "  train_transform = get_transform(config['train_transform'])\n",
        "  test_transform = get_transform(config['test_transform'])\n",
        "\n",
        "  datamodule = RESISC45DataModule(root='data',\n",
        "                                  batch_size=config['batch_size'],\n",
        "                                  train_transform=train_transform,\n",
        "                                  test_transform=test_transform,\n",
        "                                  download=False,\n",
        "                                  albumentations=config['albumentations'])\n",
        "\n",
        "  return datamodule"
      ],
      "metadata": {
        "id": "RcIbv79Mkabc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Logger"
      ],
      "metadata": {
        "id": "z53WqlOblSth"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5UndFuss0V4m"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "def get_wandb_logger(config):\n",
        "  logger = WandbLogger(project=config['project_name'], name=config['run_name'])\n",
        "  logger.experiment.config.update(config)\n",
        "\n",
        "  # Setup summary metrics\n",
        "  logger.experiment.define_metric(\"val_loss\", summary=\"min\")\n",
        "  logger.experiment.define_metric(\"val_acc\", summary=\"max\")\n",
        "  logger.experiment.define_metric(\"val_f1_score\", summary=\"max\")\n",
        "\n",
        "  return logger"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Trainer"
      ],
      "metadata": {
        "id": "7MG3BqAzhY3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_trainer(config, logger, callbacks):\n",
        "  trainer = pl.Trainer(\n",
        "    max_epochs=config['epochs'],\n",
        "    logger=logger,\n",
        "    callbacks=callbacks,\n",
        "    limit_train_batches=config['limit_train_batches'],\n",
        "    limit_val_batches=config['limit_val_batches'],\n",
        "    )\n",
        "\n",
        "  return trainer"
      ],
      "metadata": {
        "id": "acSAUhDChaJT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYFS147ugJQi"
      },
      "source": [
        "## Setup Optuna objective function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.callbacks import LearningRateMonitor\n",
        "from optuna.integration import PyTorchLightningPruningCallback\n",
        "from deepdrive_course.pl_callbacks import CollectValidationMetrics\n",
        "from deepdrive_course.resisc45.datasets import RESISC45\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "  config = dict(\n",
        "      project_name = 'resisc-optuna',\n",
        "      run_name = f'resnet50-ft-optuna_{trial.number}',\n",
        "\n",
        "      classes = RESISC45.classes,\n",
        "\n",
        "      training_type = 'full',\n",
        "      checkpoint = 'resnet50-epoch=19-val_loss=0.53.ckpt',\n",
        "\n",
        "      timm_model = 'resnet50',\n",
        "      timm_pretrained = False,\n",
        "      timm_dropout = trial.suggest_float('dropout', 0.0, 0.7),\n",
        "\n",
        "      # Study only on part of the dataset for faster training\n",
        "      limit_train_batches = 0.1,\n",
        "      limit_val_batches = 0.1,\n",
        "\n",
        "      epochs = 25,\n",
        "      batch_size = 64,\n",
        "      lr = trial.suggest_float('lr', 1e-6, 1e-2, log=True),\n",
        "      seed=42,\n",
        "\n",
        "      optimizer = trial.suggest_categorical('optimizer', ['Adam', 'SGD', 'RMSprop']),\n",
        "      optimizer_kwargs = {},\n",
        "\n",
        "      scheduler = None,\n",
        "      scheduler_interval = 'epoch',\n",
        "      scheduler_kwargs = {},\n",
        "\n",
        "      train_transform = 'albumentations_basic_aug',\n",
        "      test_transform = 'albumentations_imagenet_norm',\n",
        "      albumentations = True,\n",
        "  )\n",
        "\n",
        "  collect_val_loss = CollectValidationMetrics('val_loss')\n",
        "\n",
        "  callbacks = [\n",
        "      LearningRateMonitor(logging_interval='step'),\n",
        "      PyTorchLightningPruningCallback(trial, monitor='val_loss'),\n",
        "      collect_val_loss\n",
        "  ]\n",
        "\n",
        "  model = get_model(config)\n",
        "  logger = get_wandb_logger(config)\n",
        "  datamodule = get_datamodule(config)\n",
        "  trainer = get_trainer(config, logger, callbacks)\n",
        "\n",
        "\n",
        "  try:\n",
        "    trainer.fit(model, datamodule=datamodule)\n",
        "  except optuna.TrialPruned:\n",
        "    wandb.finish()\n",
        "    raise\n",
        "\n",
        "  wandb.finish()\n",
        "\n",
        "  # return trainer.callback_metrics[\"val_loss\"].item()\n",
        "  return min(collect_val_loss.metric_history)"
      ],
      "metadata": {
        "id": "hrS9-Ep4WyTs"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Optuna helpers"
      ],
      "metadata": {
        "id": "Wk9iOIbBh8jV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def save_sampler(sampler, file):\n",
        "  with open(file, 'wb') as f:\n",
        "    pickle.dump(sampler, f)\n",
        "\n",
        "def load_sampler(file):\n",
        "  return pickle.load(open(file, 'rb'))\n",
        "\n",
        "\n",
        "class SaveSamplerToPickleCallback:\n",
        "    def __init__(self, file):\n",
        "        self.file = file\n",
        "\n",
        "    def __call__(self, study, trial):\n",
        "      save_sampler(study.sampler, self.file)"
      ],
      "metadata": {
        "id": "2sbfgV4DmJHw"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download checkpoint"
      ],
      "metadata": {
        "id": "pVSIBCIOhTWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepdrive_course.utils import download_from_mega_nz\n",
        "\n",
        "download_from_mega_nz('https://mega.nz/file/CxtwyC4R#SfyDcxF4CKKhe2LDUT9Ssk3l6zH2Bct9pUhi7PTznjY') # resnet50-epoch=19-val_loss=0.53.ckpt"
      ],
      "metadata": {
        "id": "2TgyEKbIh7JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset (done here to do it only once)"
      ],
      "metadata": {
        "id": "zXuPLwA5jNs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir('data'):\n",
        "  RESISC45DataModule(root='data', batch_size=1, download=True).prepare_data()\n",
        "else:\n",
        "  print('Already downloaded...')"
      ],
      "metadata": {
        "id": "DHg3usb0jZsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeouE0M8E4Th"
      },
      "source": [
        "## Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzgpqdO1E7hI"
      },
      "outputs": [],
      "source": [
        "pl.seed_everything(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run study"
      ],
      "metadata": {
        "id": "H-BYIQfkh_rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import os\n",
        "\n",
        "n_trials = 40\n",
        "study_name = 'resnet50-ft'\n",
        "\n",
        "# storage = f'sqlite:////content/drive/MyDrive/Colab Notebooks/lib/optuna/{study_name}.db'\n",
        "# sampler_file = f'/content/drive/MyDrive/Colab Notebooks/lib/optuna/{study_name}_sampler.pkl'\n",
        "storage = f'sqlite:///{study_name}.db'\n",
        "sampler_file = f'{study_name}_sampler.pkl'\n",
        "\n",
        "sampler = load_sampler(sampler_file) if os.path.isfile(sampler_file) else None\n",
        "\n",
        "study = optuna.create_study(study_name=study_name,\n",
        "                            storage=storage,\n",
        "                            load_if_exists=True,\n",
        "                            sampler=sampler)\n",
        "\n",
        "optuna_callbacks = [\n",
        "    SaveSamplerToPickleCallback(study_name),\n",
        "]\n",
        "\n",
        "study.optimize(objective,\n",
        "               n_trials=n_trials,\n",
        "               callbacks=optuna_callbacks)\n",
        "\n",
        "save_sampler(study.sampler, study_name)"
      ],
      "metadata": {
        "id": "u_7kmGFgiAzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Study summary"
      ],
      "metadata": {
        "id": "HkakMFfno9Ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: {}\".format(trial.value))\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "id": "UN9XnChLo-c6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}