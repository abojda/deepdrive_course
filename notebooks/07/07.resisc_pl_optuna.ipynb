{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5DHHYu1UQIY"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywzS0HYCCJR3"
   },
   "source": [
    "**Download deepdrive_course repository when running in Google Colab (to have access to libraries)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KC6zGcGAPS5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "in_colab = \"google.colab\" in sys.modules\n",
    "\n",
    "if in_colab:\n",
    "  !git clone https://github.com/abojda/deepdrive_course.git dd_course\n",
    "  !pip install dd_course/ -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7D9wfnibxAK"
   },
   "outputs": [],
   "source": [
    "!python3 -m pip install pytorch-lightning timm opencv-python gdown patool optuna mega.py -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tZUsfbGgk9LO"
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELmrDr1Bg93Y"
   },
   "source": [
    "## wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31_obIkog9S2"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKkkQ3dZv012"
   },
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "9EonaNwiv3FI"
   },
   "outputs": [],
   "source": [
    "from deepdrive_course.resisc45.modules import ResiscLit\n",
    "from deepdrive_course.utils import (\n",
    "    download_from_mega_nz,\n",
    "    timm_prepare_params_for_training,\n",
    ")\n",
    "\n",
    "\n",
    "def get_model(config):\n",
    "    # Create TIMM model\n",
    "    timm_model = timm.create_model(\n",
    "        config[\"timm_model\"],\n",
    "        pretrained=config[\"timm_pretrained\"],\n",
    "        num_classes=len(RESISC45.classes),\n",
    "        drop_rate=config[\"timm_dropout\"],\n",
    "    )\n",
    "\n",
    "    # Create ResiscLit (pl.LightningModule)\n",
    "    if config[\"checkpoint\"] == None:\n",
    "        model = ResiscLit(timm_model, config)\n",
    "        print(\"[ResiscLit] No checkpoint - training from scratch\")\n",
    "\n",
    "    elif config[\"checkpoint\"].endswith(\".ckpt\"):\n",
    "        model = ResiscLit.load_from_checkpoint(\n",
    "            config[\"checkpoint\"], model=timm_model, config=config\n",
    "        )\n",
    "\n",
    "        print(f'[ResiscLit] Loaded local checkpoint: {config[\"checkpoint\"]}')\n",
    "\n",
    "    elif \"mega.nz\" in config[\"checkpoint\"]:\n",
    "        checkpoint_path = download_from_mega_nz(config[\"checkpoint\"])\n",
    "\n",
    "        model = ResiscLit.load_from_checkpoint(\n",
    "            checkpoint_path, model=timm_model, config=config\n",
    "        )\n",
    "\n",
    "        print(f\"[ResiscLit] Loaded mega.nz checkpoint: {checkpoint_path}\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(config[\"checkpoint\"])\n",
    "\n",
    "    # Transfer learning / full training setup\n",
    "    timm_prepare_params_for_training(model.model, config[\"training_type\"])\n",
    "    print(f'Training type: {config[\"training_type\"]}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zeqKxi1kYsY"
   },
   "source": [
    "## Setup datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RcIbv79Mkabc"
   },
   "outputs": [],
   "source": [
    "from deepdrive_course.resisc45.datamodules import RESISC45DataModule\n",
    "from deepdrive_course.resisc45.transforms import get_transform\n",
    "from deepdrive_course.utils import timm_get_pretrained_data_transform\n",
    "\n",
    "\n",
    "def get_datamodule(config):\n",
    "    train_transform = get_transform(config[\"train_transform\"])\n",
    "    test_transform = get_transform(config[\"test_transform\"])\n",
    "\n",
    "    datamodule = RESISC45DataModule(\n",
    "        root=\"data\",\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        train_transform=train_transform,\n",
    "        test_transform=test_transform,\n",
    "        download=False,\n",
    "        albumentations=config[\"albumentations\"],\n",
    "    )\n",
    "\n",
    "    return datamodule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z53WqlOblSth"
   },
   "source": [
    "## Setup Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5UndFuss0V4m"
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "\n",
    "def get_wandb_logger(config):\n",
    "    logger = WandbLogger(project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "    logger.experiment.config.update(config)\n",
    "\n",
    "    # Setup summary metrics\n",
    "    logger.experiment.define_metric(\"val_loss\", summary=\"min\")\n",
    "    logger.experiment.define_metric(\"val_acc\", summary=\"max\")\n",
    "    logger.experiment.define_metric(\"val_f1_score\", summary=\"max\")\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MG3BqAzhY3v"
   },
   "source": [
    "## Setup Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "acSAUhDChaJT"
   },
   "outputs": [],
   "source": [
    "def get_trainer(config, logger, callbacks):\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config[\"epochs\"],\n",
    "        logger=logger,\n",
    "        callbacks=callbacks,\n",
    "        limit_train_batches=config[\"limit_train_batches\"],\n",
    "        limit_val_batches=config[\"limit_val_batches\"],\n",
    "    )\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYFS147ugJQi"
   },
   "source": [
    "## Setup Optuna objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "hrS9-Ep4WyTs"
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from deepdrive_course.pl_callbacks import CollectValidationMetrics\n",
    "from deepdrive_course.resisc45.datasets import RESISC45\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    config  =  dict(\n",
    "        project_name = \"resisc-optuna\",\n",
    "        run_name = f\"resnet50-ft-optuna_{trial.number}\",\n",
    "\n",
    "        classes = RESISC45.classes,\n",
    "\n",
    "        training_type = \"full\",\n",
    "        checkpoint = \"resnet50-epoch = 19-val_loss = 0.53.ckpt\",\n",
    "\n",
    "        timm_model = \"resnet50\",\n",
    "        timm_pretrained = False,\n",
    "        timm_dropout = trial.suggest_float(\"dropout\", 0.0, 0.7),\n",
    "\n",
    "        # Study only on part of the dataset for faster training\n",
    "        limit_train_batches = 0.1,\n",
    "        limit_val_batches = 0.1,\n",
    "\n",
    "        epochs = 25,\n",
    "        batch_size = 64,\n",
    "        lr = trial.suggest_float(\"lr\", 1e-6, 1e-2, log = True),\n",
    "\n",
    "        optimizer = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\", \"RMSprop\"]),\n",
    "        optimizer_kwargs = {},\n",
    "\n",
    "        scheduler = None,\n",
    "        scheduler_interval = \"epoch\",\n",
    "        scheduler_kwargs = {},\n",
    "\n",
    "        train_transform = \"albumentations_basic_aug\",\n",
    "        test_transform = \"albumentations_imagenet_norm\",\n",
    "        albumentations = True,\n",
    "    )\n",
    "\n",
    "    collect_val_loss = CollectValidationMetrics(\"val_loss\")\n",
    "\n",
    "    callbacks = [\n",
    "        LearningRateMonitor(logging_interval=\"step\"),\n",
    "        PyTorchLightningPruningCallback(trial, monitor=\"val_loss\"),\n",
    "        collect_val_loss,\n",
    "    ]\n",
    "\n",
    "    model = get_model(config)\n",
    "    logger = get_wandb_logger(config)\n",
    "    datamodule = get_datamodule(config)\n",
    "    trainer = get_trainer(config, logger, callbacks)\n",
    "\n",
    "    try:\n",
    "        trainer.fit(model, datamodule=datamodule)\n",
    "    except optuna.TrialPruned:\n",
    "        wandb.finish()\n",
    "        raise\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    # return trainer.callback_metrics[\"val_loss\"].item()\n",
    "    return min(collect_val_loss.metric_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wk9iOIbBh8jV"
   },
   "source": [
    "## Setup Optuna helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "2sbfgV4DmJHw"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def save_sampler(sampler, file):\n",
    "    with open(file, \"wb\") as f:\n",
    "        pickle.dump(sampler, f)\n",
    "\n",
    "\n",
    "def load_sampler(file):\n",
    "    return pickle.load(open(file, \"rb\"))\n",
    "\n",
    "\n",
    "class SaveSamplerToPickleCallback:\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "\n",
    "    def __call__(self, study, trial):\n",
    "        save_sampler(study.sampler, self.file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVSIBCIOhTWe"
   },
   "source": [
    "## Download checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2TgyEKbIh7JZ"
   },
   "outputs": [],
   "source": [
    "from deepdrive_course.utils import download_from_mega_nz\n",
    "\n",
    "download_from_mega_nz(\n",
    "    \"https://mega.nz/file/CxtwyC4R#SfyDcxF4CKKhe2LDUT9Ssk3l6zH2Bct9pUhi7PTznjY\"\n",
    ")  # resnet50-epoch=19-val_loss=0.53.ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXuPLwA5jNs-"
   },
   "source": [
    "## Download dataset (done here to do it only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHg3usb0jZsA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isdir(\"data\"):\n",
    "    RESISC45DataModule(root=\"data\", batch_size=1, download=True).prepare_data()\n",
    "else:\n",
    "    print(\"Already downloaded...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeouE0M8E4Th"
   },
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzgpqdO1E7hI"
   },
   "outputs": [],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-BYIQfkh_rr"
   },
   "source": [
    "# Run study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_7kmGFgiAzG"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import os\n",
    "\n",
    "n_trials = 40\n",
    "study_name = \"resnet50-ft\"\n",
    "\n",
    "# storage = f'sqlite:////content/drive/MyDrive/Colab Notebooks/lib/optuna/{study_name}.db'\n",
    "# sampler_file = f'/content/drive/MyDrive/Colab Notebooks/lib/optuna/{study_name}_sampler.pkl'\n",
    "storage = f\"sqlite:///{study_name}.db\"\n",
    "sampler_file = f\"{study_name}_sampler.pkl\"\n",
    "\n",
    "sampler = load_sampler(sampler_file) if os.path.isfile(sampler_file) else None\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name, storage=storage, load_if_exists=True, sampler=sampler\n",
    ")\n",
    "\n",
    "optuna_callbacks = [\n",
    "    SaveSamplerToPickleCallback(study_name),\n",
    "]\n",
    "\n",
    "study.optimize(objective, n_trials=n_trials, callbacks=optuna_callbacks)\n",
    "\n",
    "save_sampler(study.sampler, study_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkakMFfno9Ox"
   },
   "source": [
    "## Study summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UN9XnChLo-c6"
   },
   "outputs": [],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
