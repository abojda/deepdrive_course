{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5DHHYu1UQIY"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywzS0HYCCJR3"
   },
   "source": [
    "**Download and install deepdrive_course repository when running in Google Colab (to have access to the libraries)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KC6zGcGAPS5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "in_colab = \"google.colab\" in sys.modules\n",
    "\n",
    "if in_colab:\n",
    "    !git clone https://github.com/abojda/deepdrive_course.git dd_course\n",
    "    !pip install dd_course/ -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tZUsfbGgk9LO"
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELmrDr1Bg93Y"
   },
   "source": [
    "## wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31_obIkog9S2"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDqZm8kj6DNK"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "cEfWZmPDGpd-"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import STL10\n",
    "\n",
    "config = dict(\n",
    "    project_name=\"stl10_supervised\",\n",
    "    run_name=\"scratch-onecycle_lr0.001-randaug_3\",\n",
    "    # run_name=\"simclr_tl-onecycle_lr0.001-randaug_3\",\n",
    "\n",
    "    image_size=96,\n",
    "    input_dim=2048,  # Resnet50 features have 2048 dimensions\n",
    "\n",
    "    timm_model=\"resnet50\",\n",
    "    timm_dropout=0.3,\n",
    "\n",
    "    checkpoint=None,\n",
    "    # checkpoint=\"https://mega.nz/file/47E1gBQD#nlwXN6ygtYUuH6K9RFFgGu7i6pmDagtfE3TTxb7wmJw\",  # SimCLR checkpoint\n",
    "\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    lr=1e-3,\n",
    "    seed=42,\n",
    "\n",
    "    optimizer=\"Adam\",\n",
    "    # optimizer=\"RMSprop\",\n",
    "    optimizer_kwargs={},\n",
    ")\n",
    "\n",
    "scheduler_config = dict(\n",
    "    # scheduler = None,\n",
    "    # scheduler_interval=\"step\",\n",
    "    # scheduler_kwargs = {}\n",
    "\n",
    "    scheduler=\"OneCycleLR\",\n",
    "    scheduler_interval=\"step\",\n",
    "    scheduler_kwargs=dict(\n",
    "        epochs=config[\"epochs\"],\n",
    "        max_lr=config[\"lr\"],\n",
    "        # steps_per_epoch is updated after training DataLoader instantiation\n",
    "    ),\n",
    ")\n",
    "\n",
    "config.update(**scheduler_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AogJQnXHAfFc"
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN8CVeZPAH4h"
   },
   "source": [
    "## Define data transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "cp2uwQuHAJ3K"
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize, RandAugment\n",
    "\n",
    "train_transform = Compose(\n",
    "    [\n",
    "        Resize((config[\"image_size\"], config[\"image_size\"])),\n",
    "        RandAugment(num_ops=3),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = Compose(\n",
    "    [\n",
    "        Resize((config[\"image_size\"], config[\"image_size\"])),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mAjLUpcm6bOO"
   },
   "source": [
    "## Initialize datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3LDfBEsq9T6J"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import STL10\n",
    "\n",
    "root = \"stl10_data\"\n",
    "\n",
    "train_ds = STL10(root=root, split=\"train\", transform=train_transform, download=True)\n",
    "\n",
    "test_ds = STL10(root=root, split=\"test\", transform=test_transform, download=True)\n",
    "\n",
    "# Update config\n",
    "config[\"classes\"] = train_ds.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDmruMyyx35I"
   },
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fS1nd4EQx35L"
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "seed_everything(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETMnWZ3Fx35N"
   },
   "source": [
    "## Initialize dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mWRbbZzx35P"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import multiprocessing\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    num_workers=multiprocessing.cpu_count(),\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=multiprocessing.cpu_count(),\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Update steps_per_epoch in configuration dictionary\n",
    "config[\"scheduler_kwargs\"][\"steps_per_epoch\"] = int(\n",
    "    len(train_dl) * config[\"limit_train_batches\"]\n",
    ")\n",
    "print(config[\"scheduler_kwargs\"][\"steps_per_epoch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4DkEgr8-JSs"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABvPg0PefGdT"
   },
   "source": [
    "## Prepare backbone model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "TJou8KeHfItI"
   },
   "outputs": [],
   "source": [
    "from deepdrive_course.stl10.modules import LitSimCLR, LitClassifier\n",
    "from deepdrive_course.utils import download_from_mega_nz\n",
    "\n",
    "\n",
    "def get_model(config):\n",
    "    if config[\"checkpoint\"] is None:\n",
    "        # We don't use pretrained model. STL10 dataset contains images from Imagenet, so that would be cheating!\n",
    "        backbone = timm.create_model(\n",
    "            config[\"timm_model\"],\n",
    "            num_classes=0,\n",
    "            pretrained=False,\n",
    "            drop_rate=config[\"timm_dropout\"],\n",
    "        )\n",
    "\n",
    "    elif config[\"checkpoint\"].endswith(\".ckpt\"):\n",
    "        simclr_model = LitSimCLR.load_from_checkpoint(config[\"checkpoint\"])\n",
    "        backbone = simclr_model.backbone\n",
    "\n",
    "    elif \"mega.nz\" in config[\"checkpoint\"]:\n",
    "        checkpoint = download_from_mega_nz(config[\"checkpoint\"])\n",
    "        simclr_model = LitSimCLR.load_from_checkpoint(checkpoint)\n",
    "        backbone = simclr_model.backbone\n",
    "\n",
    "    else:\n",
    "        raise ValueError(config[\"checkpoint\"])\n",
    "\n",
    "    return LitClassifier(backbone, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "0BF596uth-LI"
   },
   "outputs": [],
   "source": [
    "model = get_model(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q94Xme3od6Sx"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9fKtORmXTL3"
   },
   "source": [
    "## Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "nAjM9ATAXUik"
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    save_top_k=3,\n",
    "    dirpath=f'{config[\"project_name\"]}/best/{config[\"run_name\"]}',\n",
    "    filename=\"{epoch}-{val_loss:.2f}\",\n",
    ")\n",
    "\n",
    "lr_monitor_cb = LearningRateMonitor(logging_interval=\"step\")\n",
    "\n",
    "callbacks = [\n",
    "    checkpoint_cb,\n",
    "    lr_monitor_cb,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFFkDHGH4sI8"
   },
   "source": [
    "## Training and validation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AqrXLa5R4sJA"
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# Define logger\n",
    "logger = WandbLogger(project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "logger.experiment.config.update(config)\n",
    "\n",
    "# Setup summary metrics\n",
    "logger.experiment.define_metric(\"val_loss\", summary=\"min\")\n",
    "logger.experiment.define_metric(\"val_acc\", summary=\"max\")\n",
    "logger.experiment.define_metric(\"train_loss\", summary=\"min\")\n",
    "logger.experiment.define_metric(\"train_acc\", summary=\"max\")\n",
    "\n",
    "try:\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config[\"epochs\"],\n",
    "        logger=logger,\n",
    "        callbacks=callbacks,\n",
    "        num_sanity_val_steps=0,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_dl, test_dl)\n",
    "finally:\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
