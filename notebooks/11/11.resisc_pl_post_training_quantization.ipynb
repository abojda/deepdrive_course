{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bjp0Nhe7bzZ"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download deepdrive_course repository when running in Google Colab (to have access to libraries)**"
      ],
      "metadata": {
        "id": "ywzS0HYCCJR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "if in_colab:\n",
        "  !git clone https://github.com/abojda/deepdrive_course.git dd_course\n",
        "  !pip install dd_course/ -q"
      ],
      "metadata": {
        "id": "5KC6zGcGAPS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f7D9wfnibxAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "625dfaa4-811b-4518-9481-c26e60388ac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install neural-compressor -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pytorch_lightning as pl"
      ],
      "metadata": {
        "id": "KffTffu99SPg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAFYmn77yWOw"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download model weigths"
      ],
      "metadata": {
        "id": "uizPd4UuccAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepdrive_course.utils import download_from_mega_nz\n",
        "\n",
        "# resnet50-tl-ft_onecycle_lr0.0005-drop_0.3-basic_aug---val_loss=0.15.ckpt\n",
        "checkpoint = download_from_mega_nz('https://mega.nz/file/1mkigBqC#N3wyKt1N15DydkYNoniQvkcLqYCbPMDohvHY7UsVAGw')"
      ],
      "metadata": {
        "id": "oTYFT7zpceeO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model"
      ],
      "metadata": {
        "id": "PjzHL6jlcmdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepdrive_course.resisc45.modules import ResiscLit\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = ResiscLit.load_from_checkpoint(checkpoint, map_location=device)"
      ],
      "metadata": {
        "id": "Jpzmk3l68xo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset and dataloader"
      ],
      "metadata": {
        "id": "pV2w-4JJuoIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from deepdrive_course.utils import stratified_train_test_split\n",
        "from deepdrive_course.resisc45.datasets import RESISC45Albumentations\n",
        "from deepdrive_course.resisc45.transforms import get_transform\n",
        "\n",
        "train_transform = get_transform('albumentations_imagenet_norm')\n",
        "test_transform = get_transform('albumentations_imagenet_norm')\n",
        "\n",
        "full_ds = RESISC45Albumentations(root='data,',\n",
        "                                 download=True)\n",
        "\n",
        "train_ds, test_ds, _, _ = stratified_train_test_split(\n",
        "    dataset=full_ds,\n",
        "    train_size=0.8,\n",
        "    train_transform=train_transform,\n",
        "    test_transform=test_transform,\n",
        ")"
      ],
      "metadata": {
        "id": "w2ST-UCH0fmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neural_compressor.data.dataloaders.pytorch_dataloader import PyTorchDataLoader\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "train_dl_nc = PyTorchDataLoader(\n",
        "    train_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "test_dl_nc = PyTorchDataLoader(\n",
        "    test_ds,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")"
      ],
      "metadata": {
        "id": "-E1Ts7cb3MNm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantization"
      ],
      "metadata": {
        "id": "ilgGG5qctxou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from neural_compressor.config import PostTrainingQuantConfig, TuningCriterion, AccuracyCriterion\n",
        "\n",
        "accuracy_criterion = AccuracyCriterion(tolerable_loss=0.01)\n",
        "tuning_criterion = TuningCriterion(max_trials=10)\n",
        "\n",
        "conf = PostTrainingQuantConfig(\n",
        "    approach=\"static\", backend=\"default\", tuning_criterion=tuning_criterion, accuracy_criterion=accuracy_criterion\n",
        ")"
      ],
      "metadata": {
        "id": "PDV7MMgyty9M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neural_compressor.quantization import fit\n",
        "from neural_compressor import Metric\n",
        "\n",
        "accuracy_metric = Metric(\"Accuracy\")\n",
        "\n",
        "q_model = fit(model=model.model, conf=conf, calib_dataloader=train_dl_nc, eval_dataloader=test_dl_nc, eval_metric=accuracy_metric)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcVDXREFuJKL",
        "outputId": "c22c1829-3971-413d-fa5e-1892f0698393"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-07-04 13:00:26 [INFO] Start auto tuning.\n",
            "2023-07-04 13:00:26 [INFO] Create evaluation function according to evaluation dataloader and metric                and Execute the tuning process.\n",
            "2023-07-04 13:00:26 [INFO] Adaptor has 4 recipes.\n",
            "2023-07-04 13:00:26 [INFO] 0 recipes specified by user.\n",
            "2023-07-04 13:00:26 [INFO] 3 recipes require future tuning.\n",
            "2023-07-04 13:00:26 [INFO] *** Initialize auto tuning\n",
            "2023-07-04 13:00:26 [INFO] {\n",
            "2023-07-04 13:00:26 [INFO]     'PostTrainingQuantConfig': {\n",
            "2023-07-04 13:00:26 [INFO]         'AccuracyCriterion': {\n",
            "2023-07-04 13:00:26 [INFO]             'criterion': 'relative',\n",
            "2023-07-04 13:00:26 [INFO]             'higher_is_better': True,\n",
            "2023-07-04 13:00:26 [INFO]             'tolerable_loss': 0.01,\n",
            "2023-07-04 13:00:26 [INFO]             'absolute': None,\n",
            "2023-07-04 13:00:26 [INFO]             'keys': <bound method AccuracyCriterion.keys of <neural_compressor.config.AccuracyCriterion object at 0x7f2213412ec0>>,\n",
            "2023-07-04 13:00:26 [INFO]             'relative': 0.01\n",
            "2023-07-04 13:00:26 [INFO]         },\n",
            "2023-07-04 13:00:26 [INFO]         'approach': 'post_training_static_quant',\n",
            "2023-07-04 13:00:26 [INFO]         'backend': 'default',\n",
            "2023-07-04 13:00:26 [INFO]         'calibration_sampling_size': [\n",
            "2023-07-04 13:00:26 [INFO]             100\n",
            "2023-07-04 13:00:26 [INFO]         ],\n",
            "2023-07-04 13:00:26 [INFO]         'device': 'cpu',\n",
            "2023-07-04 13:00:26 [INFO]         'diagnosis': False,\n",
            "2023-07-04 13:00:26 [INFO]         'domain': 'auto',\n",
            "2023-07-04 13:00:26 [INFO]         'example_inputs': None,\n",
            "2023-07-04 13:00:26 [INFO]         'excluded_precisions': [\n",
            "2023-07-04 13:00:26 [INFO]         ],\n",
            "2023-07-04 13:00:26 [INFO]         'framework': 'pytorch_fx',\n",
            "2023-07-04 13:00:26 [INFO]         'inputs': [\n",
            "2023-07-04 13:00:26 [INFO]         ],\n",
            "2023-07-04 13:00:26 [INFO]         'model_name': '',\n",
            "2023-07-04 13:00:26 [INFO]         'op_name_dict': None,\n",
            "2023-07-04 13:00:26 [INFO]         'op_type_dict': None,\n",
            "2023-07-04 13:00:26 [INFO]         'outputs': [\n",
            "2023-07-04 13:00:26 [INFO]         ],\n",
            "2023-07-04 13:00:26 [INFO]         'quant_format': 'default',\n",
            "2023-07-04 13:00:26 [INFO]         'quant_level': 'auto',\n",
            "2023-07-04 13:00:26 [INFO]         'recipes': {\n",
            "2023-07-04 13:00:26 [INFO]             'smooth_quant': False,\n",
            "2023-07-04 13:00:26 [INFO]             'smooth_quant_args': {\n",
            "2023-07-04 13:00:26 [INFO]             },\n",
            "2023-07-04 13:00:26 [INFO]             'fast_bias_correction': False,\n",
            "2023-07-04 13:00:26 [INFO]             'weight_correction': False,\n",
            "2023-07-04 13:00:26 [INFO]             'gemm_to_matmul': True,\n",
            "2023-07-04 13:00:26 [INFO]             'graph_optimization_level': None,\n",
            "2023-07-04 13:00:26 [INFO]             'first_conv_or_matmul_quantization': True,\n",
            "2023-07-04 13:00:26 [INFO]             'last_conv_or_matmul_quantization': True,\n",
            "2023-07-04 13:00:26 [INFO]             'pre_post_process_quantization': True,\n",
            "2023-07-04 13:00:26 [INFO]             'add_qdq_pair_to_weight': False,\n",
            "2023-07-04 13:00:26 [INFO]             'optypes_to_exclude_output_quant': [\n",
            "2023-07-04 13:00:26 [INFO]             ],\n",
            "2023-07-04 13:00:26 [INFO]             'dedicated_qdq_pair': False\n",
            "2023-07-04 13:00:26 [INFO]         },\n",
            "2023-07-04 13:00:26 [INFO]         'reduce_range': None,\n",
            "2023-07-04 13:00:26 [INFO]         'TuningCriterion': {\n",
            "2023-07-04 13:00:26 [INFO]             'max_trials': 10,\n",
            "2023-07-04 13:00:26 [INFO]             'objective': 'performance',\n",
            "2023-07-04 13:00:26 [INFO]             'strategy': 'basic',\n",
            "2023-07-04 13:00:26 [INFO]             'strategy_kwargs': None,\n",
            "2023-07-04 13:00:26 [INFO]             'timeout': 0\n",
            "2023-07-04 13:00:26 [INFO]         },\n",
            "2023-07-04 13:00:26 [INFO]         'use_bf16': True\n",
            "2023-07-04 13:00:26 [INFO]     }\n",
            "2023-07-04 13:00:26 [INFO] }\n",
            "2023-07-04 13:00:26 [WARNING] [Strategy] Please install `mpi4py` correctly if using distributed tuning; otherwise, ignore this warning.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/fx/fuse.py:56: UserWarning: Passing a fuse_custom_config_dict to fuse is deprecated and will not be supported in a future version. Please pass in a FuseCustomConfig instead.\n",
            "  warnings.warn(\n",
            "2023-07-04 13:00:26 [INFO] Attention Blocks: 0\n",
            "2023-07-04 13:00:26 [INFO] FFN Blocks: 0\n",
            "2023-07-04 13:00:26 [INFO] Pass query framework capability elapsed time: 368.39 ms\n",
            "2023-07-04 13:00:26 [INFO] Get FP32 model baseline.\n",
            "2023-07-04 13:12:58 [INFO] Save tuning history to /content/nc_workspace/2023-07-04_13-00-21/./history.snapshot.\n",
            "2023-07-04 13:12:58 [INFO] FP32 baseline is: [Accuracy: 0.9638, Duration (seconds): 751.2171]\n",
            "2023-07-04 13:12:58 [INFO] Quantize the model with default config.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  warnings.warn(\n",
            "2023-07-04 13:13:23 [INFO] |*****Mixed Precision Statistics*****|\n",
            "2023-07-04 13:13:23 [INFO] +---------------------+-------+------+\n",
            "2023-07-04 13:13:23 [INFO] |       Op Type       | Total | INT8 |\n",
            "2023-07-04 13:13:23 [INFO] +---------------------+-------+------+\n",
            "2023-07-04 13:13:23 [INFO] | quantize_per_tensor |   2   |  2   |\n",
            "2023-07-04 13:13:23 [INFO] |      ConvReLU2d     |   17  |  17  |\n",
            "2023-07-04 13:13:23 [INFO] |      MaxPool2d      |   1   |  1   |\n",
            "2023-07-04 13:13:23 [INFO] |        Conv2d       |   36  |  36  |\n",
            "2023-07-04 13:13:23 [INFO] |       add_relu      |   16  |  16  |\n",
            "2023-07-04 13:13:23 [INFO] |  AdaptiveAvgPool2d  |   1   |  1   |\n",
            "2023-07-04 13:13:23 [INFO] |      dequantize     |   2   |  2   |\n",
            "2023-07-04 13:13:23 [INFO] |       dropout       |   1   |  1   |\n",
            "2023-07-04 13:13:23 [INFO] |        Linear       |   1   |  1   |\n",
            "2023-07-04 13:13:23 [INFO] +---------------------+-------+------+\n",
            "2023-07-04 13:13:23 [INFO] Pass quantize model elapsed time: 25237.54 ms\n",
            "2023-07-04 13:18:12 [INFO] Tune 1 result is: [Accuracy (int8|fp32): 0.9457|0.9638, Duration (seconds) (int8|fp32): 288.9048|751.2171], Best tune result is: n/a\n",
            "2023-07-04 13:18:12 [INFO] |***********************Tune Result Statistics**********************|\n",
            "2023-07-04 13:18:12 [INFO] +--------------------+-----------+---------------+------------------+\n",
            "2023-07-04 13:18:12 [INFO] |     Info Type      |  Baseline | Tune 1 result | Best tune result |\n",
            "2023-07-04 13:18:12 [INFO] +--------------------+-----------+---------------+------------------+\n",
            "2023-07-04 13:18:12 [INFO] |      Accuracy      |  0.9638   |    0.9457     |       n/a        |\n",
            "2023-07-04 13:18:12 [INFO] | Duration (seconds) | 751.2171  |   288.9048    |       n/a        |\n",
            "2023-07-04 13:18:12 [INFO] +--------------------+-----------+---------------+------------------+\n",
            "2023-07-04 13:18:12 [INFO] Save tuning history to /content/nc_workspace/2023-07-04_13-00-21/./history.snapshot.\n",
            "2023-07-04 13:18:12 [INFO] *** Start conservative tuning.\n",
            "2023-07-04 13:18:12 [INFO] Create evaluation function according to evaluation dataloader and metric                and Execute the tuning process.\n",
            "2023-07-04 13:18:12 [INFO] Adaptor has 4 recipes.\n",
            "2023-07-04 13:18:12 [INFO] 0 recipes specified by user.\n",
            "2023-07-04 13:18:12 [INFO] 3 recipes require future tuning.\n",
            "2023-07-04 13:18:12 [INFO] *** Initialize conservative tuning\n",
            "2023-07-04 13:18:12 [WARNING] [Strategy] Please install `mpi4py` correctly if using distributed tuning; otherwise, ignore this warning.\n",
            "2023-07-04 13:18:12 [INFO] FP32 baseline is: [Accuracy: 0.9638, Duration (seconds): 751.2171]\n",
            "2023-07-04 13:18:12 [INFO] *** Try to convert op into lower precision to improve performance.\n",
            "2023-07-04 13:18:12 [INFO] *** Start to convert op into int8.\n",
            "2023-07-04 13:18:12 [INFO] *** Try to convert all conv ops into int8.\n",
            "2023-07-04 13:18:35 [INFO] |*********Mixed Precision Statistics********|\n",
            "2023-07-04 13:18:35 [INFO] +---------------------+-------+------+------+\n",
            "2023-07-04 13:18:35 [INFO] |       Op Type       | Total | INT8 | FP32 |\n",
            "2023-07-04 13:18:35 [INFO] +---------------------+-------+------+------+\n",
            "2023-07-04 13:18:35 [INFO] | quantize_per_tensor |   2   |  2   |  0   |\n",
            "2023-07-04 13:18:35 [INFO] |      ConvReLU2d     |   17  |  17  |  0   |\n",
            "2023-07-04 13:18:35 [INFO] |      MaxPool2d      |   1   |  1   |  0   |\n",
            "2023-07-04 13:18:35 [INFO] |        Conv2d       |   36  |  36  |  0   |\n",
            "2023-07-04 13:18:35 [INFO] |       add_relu      |   16  |  16  |  0   |\n",
            "2023-07-04 13:18:35 [INFO] |  AdaptiveAvgPool2d  |   1   |  1   |  0   |\n",
            "2023-07-04 13:18:35 [INFO] |      dequantize     |   2   |  2   |  0   |\n",
            "2023-07-04 13:18:35 [INFO] |       dropout       |   1   |  1   |  0   |\n",
            "2023-07-04 13:18:35 [INFO] |        Linear       |   1   |  0   |  1   |\n",
            "2023-07-04 13:18:35 [INFO] +---------------------+-------+------+------+\n",
            "2023-07-04 13:18:35 [INFO] Pass quantize model elapsed time: 22893.89 ms\n",
            "2023-07-04 13:23:27 [INFO] Tune 2 result is: [Accuracy (int8|fp32): 0.9565|0.9638, Duration (seconds) (int8|fp32): 292.4276|751.2171], Best tune result is: [Accuracy: 0.9565, Duration (seconds): 292.4276]\n",
            "2023-07-04 13:23:27 [INFO] |***********************Tune Result Statistics**********************|\n",
            "2023-07-04 13:23:27 [INFO] +--------------------+-----------+---------------+------------------+\n",
            "2023-07-04 13:23:27 [INFO] |     Info Type      |  Baseline | Tune 2 result | Best tune result |\n",
            "2023-07-04 13:23:27 [INFO] +--------------------+-----------+---------------+------------------+\n",
            "2023-07-04 13:23:27 [INFO] |      Accuracy      |  0.9638   |    0.9565     |     0.9565       |\n",
            "2023-07-04 13:23:27 [INFO] | Duration (seconds) | 751.2171  |   292.4276    |    292.4276      |\n",
            "2023-07-04 13:23:27 [INFO] +--------------------+-----------+---------------+------------------+\n",
            "2023-07-04 13:23:27 [INFO] Save tuning history to /content/nc_workspace/2023-07-04_13-00-21/./history.snapshot.\n",
            "2023-07-04 13:23:27 [INFO] *** Do not stop the tuning process, re-quantize the ops.\n",
            "2023-07-04 13:23:27 [INFO] *** Convert all conv ops to int8 and accuracy still meet the requirements\n",
            "2023-07-04 13:23:27 [INFO] ***Current result dict_items([('conv', 'int8'), ('matmul', None), ('linear', None)])\n",
            "2023-07-04 13:23:27 [INFO] *** Try to convert all linear ops into int8.\n",
            "2023-07-04 13:23:27 [WARNING] Find evaluated tuning config, skip.\n",
            "2023-07-04 13:23:27 [INFO] *** Convert all linear ops to int8 and accuracy still meet the requirements\n",
            "2023-07-04 13:23:27 [INFO] ***Current result dict_items([('conv', 'int8'), ('matmul', None), ('linear', 'int8')])\n",
            "2023-07-04 13:23:27 [INFO] *** Ending tuning process due to no quantifiable op left.\n",
            "2023-07-04 13:23:27 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
            "2023-07-04 13:23:27 [INFO] Save deploy yaml to /content/nc_workspace/2023-07-04_13-00-21/deploy.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save models"
      ],
      "metadata": {
        "id": "tZ8lHDIzJpC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_model.save('q_model')\n",
        "torch.save(model.model, 'regular_model.pt')"
      ],
      "metadata": {
        "id": "i1dLljrIJqZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -sh regular_model.pt\n",
        "!ls -sh q_model/best_model.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABzGZgdELAc5",
        "outputId": "a198b22a-64b4-4103-b019-a7d5fba82b81"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91M regular_model.pt\n",
            "24M q_model/best_model.pt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}