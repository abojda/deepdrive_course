{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bjp0Nhe7bzZ"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywzS0HYCCJR3"
   },
   "source": [
    "**Download deepdrive_course repository when running in Google Colab (to have access to libraries)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KC6zGcGAPS5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "in_colab = \"google.colab\" in sys.modules\n",
    "\n",
    "if in_colab:\n",
    "    !git clone https://github.com/abojda/deepdrive_course.git dd_course\n",
    "    !pip install dd_course/ -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7D9wfnibxAK",
    "outputId": "625dfaa4-811b-4518-9481-c26e60388ac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install neural-compressor -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KffTffu99SPg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAFYmn77yWOw"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uizPd4UuccAM"
   },
   "source": [
    "## Download model weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oTYFT7zpceeO"
   },
   "outputs": [],
   "source": [
    "from deepdrive_course.utils import download_from_mega_nz\n",
    "\n",
    "# resnet50-tl-ft_onecycle_lr0.0005-drop_0.3-basic_aug---val_loss=0.15.ckpt\n",
    "checkpoint = download_from_mega_nz(\n",
    "    \"https://mega.nz/file/1mkigBqC#N3wyKt1N15DydkYNoniQvkcLqYCbPMDohvHY7UsVAGw\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjzHL6jlcmdg"
   },
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jpzmk3l68xo0"
   },
   "outputs": [],
   "source": [
    "from deepdrive_course.resisc45.modules import ResiscLit\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ResiscLit.load_from_checkpoint(checkpoint, map_location=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pV2w-4JJuoIE"
   },
   "source": [
    "# Load dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2ST-UCH0fmZ"
   },
   "outputs": [],
   "source": [
    "from deepdrive_course.utils import stratified_train_test_split\n",
    "from deepdrive_course.resisc45.datasets import RESISC45Albumentations\n",
    "from deepdrive_course.resisc45.transforms import get_transform\n",
    "\n",
    "train_transform = get_transform(\"albumentations_imagenet_norm\")\n",
    "test_transform = get_transform(\"albumentations_imagenet_norm\")\n",
    "\n",
    "full_ds = RESISC45Albumentations(root=\"data,\", download=True)\n",
    "\n",
    "train_ds, test_ds, _, _ = stratified_train_test_split(\n",
    "    dataset=full_ds,\n",
    "    train_size=0.8,\n",
    "    train_transform=train_transform,\n",
    "    test_transform=test_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-E1Ts7cb3MNm"
   },
   "outputs": [],
   "source": [
    "from neural_compressor.data.dataloaders.pytorch_dataloader import PyTorchDataLoader\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_dl_nc = PyTorchDataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_dl_nc = PyTorchDataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilgGG5qctxou"
   },
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PDV7MMgyty9M"
   },
   "outputs": [],
   "source": [
    "from neural_compressor.config import (\n",
    "    PostTrainingQuantConfig,\n",
    "    TuningCriterion,\n",
    "    AccuracyCriterion,\n",
    ")\n",
    "\n",
    "accuracy_criterion = AccuracyCriterion(tolerable_loss=0.01)\n",
    "tuning_criterion = TuningCriterion(max_trials=10)\n",
    "\n",
    "conf = PostTrainingQuantConfig(\n",
    "    approach=\"static\",\n",
    "    backend=\"default\",\n",
    "    tuning_criterion=tuning_criterion,\n",
    "    accuracy_criterion=accuracy_criterion,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LcVDXREFuJKL",
    "outputId": "c22c1829-3971-413d-fa5e-1892f0698393"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 13:00:26 [INFO] Start auto tuning.\n",
      "2023-07-04 13:00:26 [INFO] Create evaluation function according to evaluation dataloader and metric                and Execute the tuning process.\n",
      "2023-07-04 13:00:26 [INFO] Adaptor has 4 recipes.\n",
      "2023-07-04 13:00:26 [INFO] 0 recipes specified by user.\n",
      "2023-07-04 13:00:26 [INFO] 3 recipes require future tuning.\n",
      "2023-07-04 13:00:26 [INFO] *** Initialize auto tuning\n",
      "2023-07-04 13:00:26 [INFO] {\n",
      "2023-07-04 13:00:26 [INFO]     'PostTrainingQuantConfig': {\n",
      "2023-07-04 13:00:26 [INFO]         'AccuracyCriterion': {\n",
      "2023-07-04 13:00:26 [INFO]             'criterion': 'relative',\n",
      "2023-07-04 13:00:26 [INFO]             'higher_is_better': True,\n",
      "2023-07-04 13:00:26 [INFO]             'tolerable_loss': 0.01,\n",
      "2023-07-04 13:00:26 [INFO]             'absolute': None,\n",
      "2023-07-04 13:00:26 [INFO]             'keys': <bound method AccuracyCriterion.keys of <neural_compressor.config.AccuracyCriterion object at 0x7f2213412ec0>>,\n",
      "2023-07-04 13:00:26 [INFO]             'relative': 0.01\n",
      "2023-07-04 13:00:26 [INFO]         },\n",
      "2023-07-04 13:00:26 [INFO]         'approach': 'post_training_static_quant',\n",
      "2023-07-04 13:00:26 [INFO]         'backend': 'default',\n",
      "2023-07-04 13:00:26 [INFO]         'calibration_sampling_size': [\n",
      "2023-07-04 13:00:26 [INFO]             100\n",
      "2023-07-04 13:00:26 [INFO]         ],\n",
      "2023-07-04 13:00:26 [INFO]         'device': 'cpu',\n",
      "2023-07-04 13:00:26 [INFO]         'diagnosis': False,\n",
      "2023-07-04 13:00:26 [INFO]         'domain': 'auto',\n",
      "2023-07-04 13:00:26 [INFO]         'example_inputs': None,\n",
      "2023-07-04 13:00:26 [INFO]         'excluded_precisions': [\n",
      "2023-07-04 13:00:26 [INFO]         ],\n",
      "2023-07-04 13:00:26 [INFO]         'framework': 'pytorch_fx',\n",
      "2023-07-04 13:00:26 [INFO]         'inputs': [\n",
      "2023-07-04 13:00:26 [INFO]         ],\n",
      "2023-07-04 13:00:26 [INFO]         'model_name': '',\n",
      "2023-07-04 13:00:26 [INFO]         'op_name_dict': None,\n",
      "2023-07-04 13:00:26 [INFO]         'op_type_dict': None,\n",
      "2023-07-04 13:00:26 [INFO]         'outputs': [\n",
      "2023-07-04 13:00:26 [INFO]         ],\n",
      "2023-07-04 13:00:26 [INFO]         'quant_format': 'default',\n",
      "2023-07-04 13:00:26 [INFO]         'quant_level': 'auto',\n",
      "2023-07-04 13:00:26 [INFO]         'recipes': {\n",
      "2023-07-04 13:00:26 [INFO]             'smooth_quant': False,\n",
      "2023-07-04 13:00:26 [INFO]             'smooth_quant_args': {\n",
      "2023-07-04 13:00:26 [INFO]             },\n",
      "2023-07-04 13:00:26 [INFO]             'fast_bias_correction': False,\n",
      "2023-07-04 13:00:26 [INFO]             'weight_correction': False,\n",
      "2023-07-04 13:00:26 [INFO]             'gemm_to_matmul': True,\n",
      "2023-07-04 13:00:26 [INFO]             'graph_optimization_level': None,\n",
      "2023-07-04 13:00:26 [INFO]             'first_conv_or_matmul_quantization': True,\n",
      "2023-07-04 13:00:26 [INFO]             'last_conv_or_matmul_quantization': True,\n",
      "2023-07-04 13:00:26 [INFO]             'pre_post_process_quantization': True,\n",
      "2023-07-04 13:00:26 [INFO]             'add_qdq_pair_to_weight': False,\n",
      "2023-07-04 13:00:26 [INFO]             'optypes_to_exclude_output_quant': [\n",
      "2023-07-04 13:00:26 [INFO]             ],\n",
      "2023-07-04 13:00:26 [INFO]             'dedicated_qdq_pair': False\n",
      "2023-07-04 13:00:26 [INFO]         },\n",
      "2023-07-04 13:00:26 [INFO]         'reduce_range': None,\n",
      "2023-07-04 13:00:26 [INFO]         'TuningCriterion': {\n",
      "2023-07-04 13:00:26 [INFO]             'max_trials': 10,\n",
      "2023-07-04 13:00:26 [INFO]             'objective': 'performance',\n",
      "2023-07-04 13:00:26 [INFO]             'strategy': 'basic',\n",
      "2023-07-04 13:00:26 [INFO]             'strategy_kwargs': None,\n",
      "2023-07-04 13:00:26 [INFO]             'timeout': 0\n",
      "2023-07-04 13:00:26 [INFO]         },\n",
      "2023-07-04 13:00:26 [INFO]         'use_bf16': True\n",
      "2023-07-04 13:00:26 [INFO]     }\n",
      "2023-07-04 13:00:26 [INFO] }\n",
      "2023-07-04 13:00:26 [WARNING] [Strategy] Please install `mpi4py` correctly if using distributed tuning; otherwise, ignore this warning.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/fx/fuse.py:56: UserWarning: Passing a fuse_custom_config_dict to fuse is deprecated and will not be supported in a future version. Please pass in a FuseCustomConfig instead.\n",
      "  warnings.warn(\n",
      "2023-07-04 13:00:26 [INFO] Attention Blocks: 0\n",
      "2023-07-04 13:00:26 [INFO] FFN Blocks: 0\n",
      "2023-07-04 13:00:26 [INFO] Pass query framework capability elapsed time: 368.39 ms\n",
      "2023-07-04 13:00:26 [INFO] Get FP32 model baseline.\n",
      "2023-07-04 13:12:58 [INFO] Save tuning history to /content/nc_workspace/2023-07-04_13-00-21/./history.snapshot.\n",
      "2023-07-04 13:12:58 [INFO] FP32 baseline is: [Accuracy: 0.9638, Duration (seconds): 751.2171]\n",
      "2023-07-04 13:12:58 [INFO] Quantize the model with default config.\n",
      "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n",
      "2023-07-04 13:13:23 [INFO] |*****Mixed Precision Statistics*****|\n",
      "2023-07-04 13:13:23 [INFO] +---------------------+-------+------+\n",
      "2023-07-04 13:13:23 [INFO] |       Op Type       | Total | INT8 |\n",
      "2023-07-04 13:13:23 [INFO] +---------------------+-------+------+\n",
      "2023-07-04 13:13:23 [INFO] | quantize_per_tensor |   2   |  2   |\n",
      "2023-07-04 13:13:23 [INFO] |      ConvReLU2d     |   17  |  17  |\n",
      "2023-07-04 13:13:23 [INFO] |      MaxPool2d      |   1   |  1   |\n",
      "2023-07-04 13:13:23 [INFO] |        Conv2d       |   36  |  36  |\n",
      "2023-07-04 13:13:23 [INFO] |       add_relu      |   16  |  16  |\n",
      "2023-07-04 13:13:23 [INFO] |  AdaptiveAvgPool2d  |   1   |  1   |\n",
      "2023-07-04 13:13:23 [INFO] |      dequantize     |   2   |  2   |\n",
      "2023-07-04 13:13:23 [INFO] |       dropout       |   1   |  1   |\n",
      "2023-07-04 13:13:23 [INFO] |        Linear       |   1   |  1   |\n",
      "2023-07-04 13:13:23 [INFO] +---------------------+-------+------+\n",
      "2023-07-04 13:13:23 [INFO] Pass quantize model elapsed time: 25237.54 ms\n",
      "2023-07-04 13:18:12 [INFO] Tune 1 result is: [Accuracy (int8|fp32): 0.9457|0.9638, Duration (seconds) (int8|fp32): 288.9048|751.2171], Best tune result is: n/a\n",
      "2023-07-04 13:18:12 [INFO] |***********************Tune Result Statistics**********************|\n",
      "2023-07-04 13:18:12 [INFO] +--------------------+-----------+---------------+------------------+\n",
      "2023-07-04 13:18:12 [INFO] |     Info Type      |  Baseline | Tune 1 result | Best tune result |\n",
      "2023-07-04 13:18:12 [INFO] +--------------------+-----------+---------------+------------------+\n",
      "2023-07-04 13:18:12 [INFO] |      Accuracy      |  0.9638   |    0.9457     |       n/a        |\n",
      "2023-07-04 13:18:12 [INFO] | Duration (seconds) | 751.2171  |   288.9048    |       n/a        |\n",
      "2023-07-04 13:18:12 [INFO] +--------------------+-----------+---------------+------------------+\n",
      "2023-07-04 13:18:12 [INFO] Save tuning history to /content/nc_workspace/2023-07-04_13-00-21/./history.snapshot.\n",
      "2023-07-04 13:18:12 [INFO] *** Start conservative tuning.\n",
      "2023-07-04 13:18:12 [INFO] Create evaluation function according to evaluation dataloader and metric                and Execute the tuning process.\n",
      "2023-07-04 13:18:12 [INFO] Adaptor has 4 recipes.\n",
      "2023-07-04 13:18:12 [INFO] 0 recipes specified by user.\n",
      "2023-07-04 13:18:12 [INFO] 3 recipes require future tuning.\n",
      "2023-07-04 13:18:12 [INFO] *** Initialize conservative tuning\n",
      "2023-07-04 13:18:12 [WARNING] [Strategy] Please install `mpi4py` correctly if using distributed tuning; otherwise, ignore this warning.\n",
      "2023-07-04 13:18:12 [INFO] FP32 baseline is: [Accuracy: 0.9638, Duration (seconds): 751.2171]\n",
      "2023-07-04 13:18:12 [INFO] *** Try to convert op into lower precision to improve performance.\n",
      "2023-07-04 13:18:12 [INFO] *** Start to convert op into int8.\n",
      "2023-07-04 13:18:12 [INFO] *** Try to convert all conv ops into int8.\n",
      "2023-07-04 13:18:35 [INFO] |*********Mixed Precision Statistics********|\n",
      "2023-07-04 13:18:35 [INFO] +---------------------+-------+------+------+\n",
      "2023-07-04 13:18:35 [INFO] |       Op Type       | Total | INT8 | FP32 |\n",
      "2023-07-04 13:18:35 [INFO] +---------------------+-------+------+------+\n",
      "2023-07-04 13:18:35 [INFO] | quantize_per_tensor |   2   |  2   |  0   |\n",
      "2023-07-04 13:18:35 [INFO] |      ConvReLU2d     |   17  |  17  |  0   |\n",
      "2023-07-04 13:18:35 [INFO] |      MaxPool2d      |   1   |  1   |  0   |\n",
      "2023-07-04 13:18:35 [INFO] |        Conv2d       |   36  |  36  |  0   |\n",
      "2023-07-04 13:18:35 [INFO] |       add_relu      |   16  |  16  |  0   |\n",
      "2023-07-04 13:18:35 [INFO] |  AdaptiveAvgPool2d  |   1   |  1   |  0   |\n",
      "2023-07-04 13:18:35 [INFO] |      dequantize     |   2   |  2   |  0   |\n",
      "2023-07-04 13:18:35 [INFO] |       dropout       |   1   |  1   |  0   |\n",
      "2023-07-04 13:18:35 [INFO] |        Linear       |   1   |  0   |  1   |\n",
      "2023-07-04 13:18:35 [INFO] +---------------------+-------+------+------+\n",
      "2023-07-04 13:18:35 [INFO] Pass quantize model elapsed time: 22893.89 ms\n",
      "2023-07-04 13:23:27 [INFO] Tune 2 result is: [Accuracy (int8|fp32): 0.9565|0.9638, Duration (seconds) (int8|fp32): 292.4276|751.2171], Best tune result is: [Accuracy: 0.9565, Duration (seconds): 292.4276]\n",
      "2023-07-04 13:23:27 [INFO] |***********************Tune Result Statistics**********************|\n",
      "2023-07-04 13:23:27 [INFO] +--------------------+-----------+---------------+------------------+\n",
      "2023-07-04 13:23:27 [INFO] |     Info Type      |  Baseline | Tune 2 result | Best tune result |\n",
      "2023-07-04 13:23:27 [INFO] +--------------------+-----------+---------------+------------------+\n",
      "2023-07-04 13:23:27 [INFO] |      Accuracy      |  0.9638   |    0.9565     |     0.9565       |\n",
      "2023-07-04 13:23:27 [INFO] | Duration (seconds) | 751.2171  |   292.4276    |    292.4276      |\n",
      "2023-07-04 13:23:27 [INFO] +--------------------+-----------+---------------+------------------+\n",
      "2023-07-04 13:23:27 [INFO] Save tuning history to /content/nc_workspace/2023-07-04_13-00-21/./history.snapshot.\n",
      "2023-07-04 13:23:27 [INFO] *** Do not stop the tuning process, re-quantize the ops.\n",
      "2023-07-04 13:23:27 [INFO] *** Convert all conv ops to int8 and accuracy still meet the requirements\n",
      "2023-07-04 13:23:27 [INFO] ***Current result dict_items([('conv', 'int8'), ('matmul', None), ('linear', None)])\n",
      "2023-07-04 13:23:27 [INFO] *** Try to convert all linear ops into int8.\n",
      "2023-07-04 13:23:27 [WARNING] Find evaluated tuning config, skip.\n",
      "2023-07-04 13:23:27 [INFO] *** Convert all linear ops to int8 and accuracy still meet the requirements\n",
      "2023-07-04 13:23:27 [INFO] ***Current result dict_items([('conv', 'int8'), ('matmul', None), ('linear', 'int8')])\n",
      "2023-07-04 13:23:27 [INFO] *** Ending tuning process due to no quantifiable op left.\n",
      "2023-07-04 13:23:27 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2023-07-04 13:23:27 [INFO] Save deploy yaml to /content/nc_workspace/2023-07-04_13-00-21/deploy.yaml\n"
     ]
    }
   ],
   "source": [
    "from neural_compressor.quantization import fit\n",
    "from neural_compressor import Metric\n",
    "\n",
    "accuracy_metric = Metric(\"Accuracy\")\n",
    "\n",
    "q_model = fit(\n",
    "    model=model.model,\n",
    "    conf=conf,\n",
    "    calib_dataloader=train_dl_nc,\n",
    "    eval_dataloader=test_dl_nc,\n",
    "    eval_metric=accuracy_metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZ8lHDIzJpC2"
   },
   "source": [
    "# Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1dLljrIJqZi"
   },
   "outputs": [],
   "source": [
    "q_model.save(\"q_model\")\n",
    "torch.save(model.model, \"regular_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABzGZgdELAc5",
    "outputId": "a198b22a-64b4-4103-b019-a7d5fba82b81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91M regular_model.pt\n",
      "24M q_model/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "!ls -sh regular_model.pt\n",
    "!ls -sh q_model/best_model.pt"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
